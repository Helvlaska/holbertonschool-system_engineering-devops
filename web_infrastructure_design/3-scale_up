# 3. Mise Ã  lâ€™Ã©chelle (Scale up)

## ðŸ“Œ Description

Cette infrastructure reprend la version sÃ©curisÃ©e et monitorÃ©e (tÃ¢che 2) mais elle est amÃ©liorÃ©e pour gÃ©rer une charge plus importante et rÃ©duire encore les SPOF.

Elle comprend :

- **Un serveur supplÃ©mentaire** pour renforcer la capacitÃ©.
- **Deux load balancers** configurÃ©s en cluster (HAProxy en mode haute disponibilitÃ©).
- **Composants sÃ©parÃ©s** sur des serveurs dÃ©diÃ©s :
  - Un ou plusieurs serveurs web (Nginx).
  - Un ou plusieurs serveurs applicatifs.
  - Des serveurs dÃ©diÃ©s Ã  la base de donnÃ©es.

---

## ðŸŒ Fonctionnement (flux utilisateur)

1. Le client tape `https://www.foobar.com`.
2. Le DNS rÃ©sout le domaine vers **lâ€™adresse IP du cluster de load balancers**.
3. Les **deux load balancers** assurent la rÃ©partition du trafic (active-active ou active-passive).
4. Les serveurs sont dÃ©sormais spÃ©cialisÃ©s :
   - **Serveurs web (Nginx)** gÃ¨rent uniquement les requÃªtes HTTP.
   - **Serveurs applicatifs** exÃ©cutent le code.
   - **Serveurs MySQL** gÃ¨rent la base de donnÃ©es (un primaire, plusieurs rÃ©pliques).
5. La scalabilitÃ© est amÃ©liorÃ©e : on peut ajouter des serveurs Ã  chaque couche sans tout redÃ©ployer.

---

## ðŸ”§ Explication des ajouts

- **Deux load balancers en cluster** : Ã©vitent quâ€™un seul LB devienne un SPOF.
- **SÃ©paration des rÃ´les** : plus efficace que dâ€™avoir web/app/DB mÃ©langÃ©s sur les mÃªmes serveurs.
- **Nouveau serveur ajoutÃ©** : permet dâ€™absorber davantage de trafic.

---

## âš ï¸ ProblÃ¨mes et limites

- La complexitÃ© augmente (configuration, synchronisation, monitoring).
- La base MySQL reste limitÃ©e par le fait quâ€™un seul serveur accepte les Ã©critures.
- Les coÃ»ts sont plus Ã©levÃ©s (plus de serveurs + cluster de load balancers).

---

## ðŸ“¸ Diagramme (Scale up)

```mermaid
flowchart TD
    U["Client"] --> DNS[(DNS)]
    DNS --> LB1["Load Balancer 1 - HAProxy"]
    DNS --> LB2["Load Balancer 2 - HAProxy"]

    LB1 --> WEB1
    LB1 --> WEB2
    LB2 --> WEB1
    LB2 --> WEB2

    subgraph WEB1 ["Web Server 1"]
        N1["Nginx"]
    end

    subgraph WEB2 ["Web Server 2"]
        N2["Nginx"]
    end

    %% Web servers -> App servers
    WEB1 --> APP1
    WEB2 --> APP2

    subgraph APP1 ["App Server 1"]
        A1["Application Logic"]
    end

    subgraph APP2 ["App Server 2"]
        A2["Application Logic"]
    end

    %% App servers -> DB
    APP1 --> DB1
    APP2 --> DB2

    subgraph DB1 ["MySQL Primary"]
    end

    subgraph DB2 ["MySQL Replica"]
    end

    %% DB replication
    DB1 --> DB2
```
